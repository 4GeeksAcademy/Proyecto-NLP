{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                             https://www.hvper.com/     True\n",
                            "2                 https://briefingday.com/m/v4n3i4f3     True\n",
                            "3   https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                        https://briefingday.com/fan     True"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Your code here\n",
                "import pandas as pd\n",
                "\n",
                "df = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/NLP-project-tutorial/main/url_spam.csv')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Paso 2: Preprocesa los enlaces\n",
                "Utiliza lo visto en este módulo para transformar los datos para compatibilizarlos con el modelo que queremos entrenar. Segmenta las URLs en partes según sus signos de puntuación, elimina las stopwords, lematiza, etcétera.\n",
                "\n",
                "Asegúrate de dividir convenientemente el conjunto de datos en train y test como hemos visto en lecciones anteriores."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "\n",
                "def segment_url(url):\n",
                "    return re.split(r'\\W+', url)\n",
                "\n",
                "df['segmented_url'] = df['url'].apply(segment_url)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Segmentación de URLs por signos de puntuación: se divide las URLs en partes en función de los signos de puntuación, como el punto, barra, y guiones. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting nltk\n",
                        "  Downloading nltk-3.8.2-py3-none-any.whl.metadata (2.9 kB)\n",
                        "Requirement already satisfied: click in c:\\users\\rgarciamontero\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
                        "Requirement already satisfied: joblib in c:\\users\\rgarciamontero\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
                        "Collecting regex>=2021.8.3 (from nltk)\n",
                        "  Downloading regex-2024.7.24-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
                        "Collecting tqdm (from nltk)\n",
                        "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
                        "Requirement already satisfied: colorama in c:\\users\\rgarciamontero\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
                        "Downloading nltk-3.8.2-py3-none-any.whl (1.5 MB)\n",
                        "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
                        "   ---------------------------------------- 1.5/1.5 MB 15.9 MB/s eta 0:00:00\n",
                        "Downloading regex-2024.7.24-cp312-cp312-win_amd64.whl (269 kB)\n",
                        "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
                        "Installing collected packages: tqdm, regex, nltk\n",
                        "Successfully installed nltk-3.8.2 regex-2024.7.24 tqdm-4.66.5\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip install nltk"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to\n",
                        "[nltk_data]     C:\\Users\\rgarciamontero\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
                    ]
                }
            ],
            "source": [
                "import nltk\n",
                "from nltk.corpus import stopwords\n",
                "\n",
                "nltk.download('stopwords')\n",
                "stop_words = set(stopwords.words('english'))\n",
                "\n",
                "def remove_stopwords(words):\n",
                "    return [word for word in words if word.lower() not in stop_words]\n",
                "\n",
                "df['filtered_url'] = df['segmented_url'].apply(remove_stopwords)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Eliminar stopwords: Utilizando la biblioteca nltk, puedes eliminar las stopwords comunes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package wordnet to\n",
                        "[nltk_data]     C:\\Users\\rgarciamontero\\AppData\\Roaming\\nltk_data...\n"
                    ]
                }
            ],
            "source": [
                "from nltk.stem import WordNetLemmatizer\n",
                "\n",
                "nltk.download('wordnet')\n",
                "lemmatizer = WordNetLemmatizer()\n",
                "\n",
                "def lemmatize_words(words):\n",
                "    return [lemmatizer.lemmatize(word) for word in words]\n",
                "\n",
                "df['lemmatized_url'] = df['filtered_url'].apply(lemmatize_words)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Lematización: Utilizando WordNetLemmatizer de nltk para lematizar las palabras."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: scikit-learn in c:\\users\\rgarciamontero\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.1)\n",
                        "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\rgarciamontero\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
                        "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rgarciamontero\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
                        "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rgarciamontero\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rgarciamontero\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip install scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "      <th>segmented_url</th>\n",
                            "      <th>filtered_url</th>\n",
                            "      <th>lemmatized_url</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>True</td>\n",
                            "      <td>[https, briefingday, us8, list, manage, com, u...</td>\n",
                            "      <td>[https, briefingday, us8, list, manage, com, u...</td>\n",
                            "      <td>[http, briefingday, us8, list, manage, com, un...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>True</td>\n",
                            "      <td>[https, www, hvper, com, ]</td>\n",
                            "      <td>[https, www, hvper, com, ]</td>\n",
                            "      <td>[http, www, hvper, com, ]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>True</td>\n",
                            "      <td>[https, briefingday, com, m, v4n3i4f3]</td>\n",
                            "      <td>[https, briefingday, com, v4n3i4f3]</td>\n",
                            "      <td>[http, briefingday, com, v4n3i4f3]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>False</td>\n",
                            "      <td>[https, briefingday, com, n, 20200618, m, comm...</td>\n",
                            "      <td>[https, briefingday, com, n, 20200618, comment...</td>\n",
                            "      <td>[http, briefingday, com, n, 20200618, commentf...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>True</td>\n",
                            "      <td>[https, briefingday, com, fan]</td>\n",
                            "      <td>[https, briefingday, com, fan]</td>\n",
                            "      <td>[http, briefingday, com, fan]</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam  \\\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...     True   \n",
                            "1                             https://www.hvper.com/     True   \n",
                            "2                 https://briefingday.com/m/v4n3i4f3     True   \n",
                            "3   https://briefingday.com/n/20200618/m#commentform    False   \n",
                            "4                        https://briefingday.com/fan     True   \n",
                            "\n",
                            "                                       segmented_url  \\\n",
                            "0  [https, briefingday, us8, list, manage, com, u...   \n",
                            "1                         [https, www, hvper, com, ]   \n",
                            "2             [https, briefingday, com, m, v4n3i4f3]   \n",
                            "3  [https, briefingday, com, n, 20200618, m, comm...   \n",
                            "4                     [https, briefingday, com, fan]   \n",
                            "\n",
                            "                                        filtered_url  \\\n",
                            "0  [https, briefingday, us8, list, manage, com, u...   \n",
                            "1                         [https, www, hvper, com, ]   \n",
                            "2                [https, briefingday, com, v4n3i4f3]   \n",
                            "3  [https, briefingday, com, n, 20200618, comment...   \n",
                            "4                     [https, briefingday, com, fan]   \n",
                            "\n",
                            "                                      lemmatized_url  \n",
                            "0  [http, briefingday, us8, list, manage, com, un...  \n",
                            "1                          [http, www, hvper, com, ]  \n",
                            "2                 [http, briefingday, com, v4n3i4f3]  \n",
                            "3  [http, briefingday, com, n, 20200618, commentf...  \n",
                            "4                      [http, briefingday, com, fan]  "
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "#train y test\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X = df['lemmatized_url'].apply(lambda x: ' '.join(x))  # Únelos de nuevo en texto\n",
                "y = df['is_spam']  # Suponiendo que 'label' es la columna objetivo\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Paso 3: Construye un SVM\n",
                "Comienza a resolver el problema implementando un SVM con los parámetros por defecto. Entrénalo y analiza sus resultados.\n",
                "\n",
                "Paso 4: Optimiza el modelo anterior\n",
                "Después de entrenar el SVM, optimiza sus hiperparámetros utilizando un grid search o un random search."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracy: 0.9466666666666667\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "       False       0.96      0.97      0.97       455\n",
                        "        True       0.91      0.87      0.89       145\n",
                        "\n",
                        "    accuracy                           0.95       600\n",
                        "   macro avg       0.93      0.92      0.93       600\n",
                        "weighted avg       0.95      0.95      0.95       600\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import classification_report, accuracy_score\n",
                "\n",
                "\n",
                "#vectorizacion de los textos\n",
                "\n",
                "tfidf_vectorizer = TfidfVectorizer()\n",
                "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
                "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
                "\n",
                "# Entrenar el SVM\n",
                "\n",
                "svm = SVC()\n",
                "svm.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Evaluar el modelo\n",
                "\n",
                "y_pred = svm.predict(X_test_tfidf)\n",
                "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
                "print(classification_report(y_test, y_pred))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
                        "Optimized Accuracy: 0.9466666666666667\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "       False       0.98      0.95      0.96       455\n",
                        "        True       0.86      0.92      0.89       145\n",
                        "\n",
                        "    accuracy                           0.95       600\n",
                        "   macro avg       0.92      0.94      0.93       600\n",
                        "weighted avg       0.95      0.95      0.95       600\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "# Optimizacion del modelo\n",
                "\n",
                "# Define los parámetros a optimizar.\n",
                "parameter_grid = {\n",
                "    'C': [0.1, 1, 10],\n",
                "    'kernel': ['linear', 'rbf', 'poly'],\n",
                "    'gamma': ['scale', 'auto']\n",
                "}\n",
                "\n",
                "# Configura y ejecuta el grid search utilizando los parámetros definidos.\n",
                "grid_search = GridSearchCV(SVC(), parameter_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
                "grid_search.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Obtener y mostrar los mejores parámetros encontrados\n",
                "best_params = grid_search.best_params_\n",
                "print(f\"Best parameters: {best_params}\")\n",
                "\n",
                "# Entrenar el modelo con los mejores hiperparámetros\n",
                "best_svm = grid_search.best_estimator_\n",
                "best_svm.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Evaluar el modelo optimizado\n",
                "best_y_pred = best_svm.predict(X_test_tfidf)\n",
                "print(f\"Optimized Accuracy: {accuracy_score(y_test, best_y_pred)}\")\n",
                "print(classification_report(y_test, best_y_pred))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Paso 5: Guarda el modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "import joblib\n",
                "\n",
                "# Suponiendo que 'best_svm' es tu modelo entrenado y optimizado\n",
                "joblib.dump(best_svm, 'svm_model.pkl')\n",
                "\n",
                "# Cargar el modelo guardado\n",
                "loaded_svm = joblib.load('svm_model.pkl')\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
